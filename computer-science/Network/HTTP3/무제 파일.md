
## ⛔️ HTTP/2.0 의 한계 : 

HTTP/2.0은 정말 많은 성능의 향상을 이루어냈습니다. 그러나 이런 HTTP/2.0에도 한계가 존재했습니다. 바로 이 프로토콜 또한 TCP 위에서 동작한다는 점입니다. HTTP/2.0이 아무리 많은 발전을 이루어내도, 결국 TCP 위에서 동작하기 때문에 TCP가 가진 한계를 벗어날 수가 없었습니다. 그래서 결국 TCP를 버리고 UDP를 선택하는 움직임이 생겼습니다. 그렇게 UDP 위에 만들어진 프로토콜이 QUIC입니다. 
해당 내용을 알아보기 전에 H2의 한계를 알아볼 것입니다. 어쩌면 H2의 한계를 알아보는 것은 곧 TCP의 한계를 알아보는 것일지도 모르겠습니다. 여러가지 한계점이 있겠지만, 이 시간 다뤄볼 내용은 크게 2가지 입니다. 


1)TCP의 느린 연결 수립 :
2)TCP레벨에서의 HOLB(Head Of Line Blocking) :

<br>

### 1) TCP의 느린 연결수립 : 

TCP는 데이터 전송의 신중함을 위해서 연결 수립에 긴 시간이 소요됩니다. 이것을 위해서 진행되는 것이 3-way-handshake입니다. 여기에 더해 보안까지 신경을 쓰게되면 연결수립 과정이 더 길어집니다. 이런 과정들이 왜 필요하게 된 것인지에 대해서 이해해보고, 그 한계점을 알아보겠습니다. 

3-way-handshake는 왜 느릴까요? 이것은 왜 필요한 것일까요? 이를 이해하기 위해선 먼저 TCP를 간략히 이해할 필요가 있겠습니다. TCP는 신뢰성, 안정성을 중요하게 생각하는 프로토콜입니다. 내가 데이터를 보냈을 때, 이것이 중간에 손실되지 않고 확실하게 받고, 보내겠다. <u>"확실하고, 안전하게."</u> 여기에 힘을 쏟은 프로토콜이 TCP입니다. 

#### TCP는 어떻게 신뢰성을 보장하는가? 

TCP가 확실하게 데이터를 주고 받기 위해서 사용하는 것이 <u>일련번호(sequence number)</u>입니다. TCP에서는 데이터를 보낼 때, 여러 개의 패킷으로 나누어보냅니다. 한번에 많은 데이터를 보내는 경우 대역폭을 많이 차지할 수 있기 때문에 그렇습니다. 이때, 패킷에 sequence number가 새겨짐으로써 중간에 손실된 데이터가 없도록 만듭니다. 
예를 들어서 A 패킷을 a와 b로 나누었다고 해보겠습니다. a에 새겨져있는 일련번호는 1번이고, b에 새겨진 번호는 2번입니다. 클라이언트 쪽에서 처음에는 1번이 새겨진 데이터를 받았습니다. 그럼 그 다음에는 2번이 새겨진 데이터를 받을 것을 기대할 수 있습니다. 그런데 7번이 새겨진 데이터가 온 것입니다. "어 이거 이상해! 다시 데이터 제대로 보내줘." 라고 말할 수 있는 근거가 sequence number로 부터 제공되는 것입니다. 이 sequence number 덕분에 데이터를 신뢰하고 받을 수 있게 된 것입니다. 

#### TCP에 3-way-handshake는 왜 필요한가? 

이렇게 sequence number를 사전에 확립하기 위해서 진행하는 과정이 3-way-handshake입니다. 조금 더 설명해보겠습니다. TCP는 양방향 통신입니다. 때문에 클라이언트도, 서버도 데이터를 보낼 수 있습니다. 그렇다면 양측 모두가 이용가능한 일련번호가 필요할 것입니다. 이때 맨처음에 생성하는 일련번호를 ISN(Initial Sequence Number)라고 합니다. 그리고 둘 다 서로의 초기 일련번호를 알 필요가 있습니다. 이것을 위해서 3-way-handshake가 필요한 것입니다. 예를 들어보면 다음과 같습니다. 

```
영희 -> 철수 : 철수야 내 ISN은 256란다.(SYN)
영희 <- 철수 : 너의 ISN을 받았어. 256구나 알겠어(ACKnowledge)!나는 257(256+1)을 받을 준비가 되었어(ACK)
영희 <- 철수 : 영희야 그리고 내 ISN은 567이야 (SYN)
영희 -> 철수 : 너의 ISN을 받았어. 567이구나 알겠어(ACKnowledge)!나는 568(567+1)을 받을 준비가 되었어(ACK)
```

이런 방식으로 3-way-handshake과정이 진행되고, 이 과정을 통해서 양측은 서로의 일련번호를 수립하게 됩니다. 실제로는 철수가 영희에게 ISN을 알았다고 말하는 부분과, 자신의 ISN을 영희에게 전달하는 부분은 동시에 진행됩니다. 이제부터 양측은 데이터가 손실될 걱정 없이 마음 놓고 데이터를 보낼 수 있게 되었습니다. 일련번호가 있으니까요! 문제가 생기면 데이터를 다시 요청하면됩니다. 이런 이유로 3-way-handshake가 필요합니다. 

위의 내용을 통해서 알게 되셨겠지만, TCP에서 연결수립을 위해서 3-way-handshake는 필요한 과정입니다. 하지만 여기에 더해 보안을 신경 쓴 TLS handshake가 더해지면 어떻게될까요? 
<img src="https://velog.velcdn.com/images/yesbb/post/571fdafb-3f3c-44ea-8a70-927670f96de1/image.gif" width="40%" />


[Why do we need a 3-way handshake? Why not just 2-way?](https://networkengineering.stackexchange.com/a/24072/85765)
[Why does TCP even need a 3-way handshake?](https://pcarleton.com/2018/06/06/why-does-tcp-need-a-3-way-handshake-anyway/)


#### TLS handshake :  


TLS는 보안 통신을 위해서 설계된 프로토콜입니다. 그리고 TLS handshake란 이 TLS를 이용해서 안전한 통신을 하기 위한 과정입니다. 이 과정을 통해서 클라이언트와 서버 간에 필요한 암호화 및 인증 정보를 교환하고, 서로간의 통신을 위한 암호화 키를 교환합니다. 이런 과정을 통해서 안전한 통신을 시작할 수 있습니다. 

구체적인 TLS 핸드쉐이크의 과정을 설명하는 것은 [링크](https://www.cloudflare.com/ko-kr/learning/ssl/what-happens-in-a-tls-handshake/)로 대체하도록 하겠습니다. 결국 이 과정을 소개함으로써 제가 말하고 싶은 것은 <u>TLS 핸드쉐이크는 3-way-Handshake가 진행된 다음에 추가적으로 실행된다</u>. <u>고로 전체적인 RTT가 증가한다.</u>는 것입니다. 아래 사진을 보겠습니다. 

![](https://velog.velcdn.com/images/yesbb/post/9c5baab5-40ed-4109-bb94-dcbfa09982de/image.png)

보시면 맨 위에서 3-way-handshake가 진행된 다음, 그 연결에 이어 또 보안을 위한 핸드쉐이크가 진행됩니다. TLS핸드쉐이크가 마무리 된 이후에야 본격적으로 클라이언트가 서버에게 원하는 요청을 시작할 수 있습니다. TLS 1.2버전에 비해서 TLS 1.3버전의 RTT가 줄어들기는 했지만, 마찬가지로 3-way-handshake 이후에 추가적인 handshake 과정이 필요합니다. 결론적으로 production에서는 https를 사용하지 않는 경우가 거의 없고, 그렇다면 TCP에서의 연결 수립은 TLS 1.2버전까지는 3RTT, TLS 1.3 버전이 되어 좋아봐야 2RTT가 걸립니다. 이것보다 더 개선될 수는 없을까요? HTTP3는 가능합니다. 

참고 : [Key differences Between TLS 1.2 and TLS 1.3](https://www.a10networks.com/glossary/key-differences-between-tls-1-2-and-tls-1-3/)

<br>

### 2) TCP레벨에서의 HOLB(Head Of Line Blocking) : 

이번엔 TCP가 가지고 있는 HOLB의 문제점을 알아보겠습니다. H2는 H1에 비해 엄청난 속도 향상을 이루었습니다. 하지만, H2도 H1보다 속도가 느린 순간이 있었습니다. 바로 패킷이 손상되었을 때 입니다. 

![](https://velog.velcdn.com/images/yesbb/post/6155eb4a-6d65-49c3-9c2e-603872b1d286/image.png)

위 그림에는 3가지 스트림이 전송되고 있습니다. stream5, stream7,stream9. 그런데 이 중 맨 앞에 있던 stream5/style.css - headers가 손상되었다고 해보겠습니다. 그럼 제대로 된 패킷을 전달받지 못한 것을 알게된 클라이언트는 이를 서버에게 알립니다. 그리고 서버는 해당 stream5 - headers를 재전송하게 될 것입니다. 

![](https://velog.velcdn.com/images/yesbb/post/84757ec8-5161-484c-a343-8e6f44a12d8a/image.png)


stream5가 제일 마지막 순번으로 전송되는 모습을 볼 수 있습니다. 만약 또 다른 패킷 손상이 일어나지 않았다면 stream7과 stream9는 클라이언트에 도착해서 흩어져있던 프레임들이 재구성되어 있을 것입니다. 하지만, 문제는 TCP는 순서를 보장하는 프로토콜이라는 것입니다. 응답 데이터들은 queue 되어야 하기 때문에 당장에 사용할 수가 없는 한계가 있습니다. 만약 똑같은 상황이 MultiConnection을 사용하는 H/1.1에서 일어났다면, 상황은 달랐을 것입니다. 

H/1.1에서는 style.css 파일을 요청한 부분에서 문제가 생겼으면 해당 TCP 요청만 재전송하면 됩니다. 그리고 다른 script, img 파일의 TCP요청은 먼저 도착해서 클라이언트에서 사용되고 있었을 것입니다. 딜레이되는 것은 딱 style.css파일밖에 없는 것입니다. 

H2는 Multiplexing을 통해서 <u>HTTP 레벨에서의 Blocking</u>을 해결했습니다. 한가지 리소스에서 발생한 지연이, 다른 리소스에 영향이 미치지 않도록 만들어주었지요. 하지만, <u>TCP 레벨에서의 Blocking</u>은 여전히 남아있었습니다. 하나의 스트림에서 발생한 패킷 손상이 다른 스트림에도 영향을 미치는 한계점이 있었던 것입니다. 

<br/>

이렇게 HTTP2의 한계점까지 알아보았습니다. HTTP1.1버전은 약 15년간 표준의 자리를 유지해왔습니다. 하지만 H2는 약 6-7년의 시간만에 표준의 자리를 내어주게 됩니다. 



## ✨HTTP/3 - HTTP over QUIC 

HTTP3는 2020년에 발표되었고, 2022년 6월에 표준화가 완성되었습니다. 위에서 언급했다시피 HTTP/3는 TCP를 선택하지 않았습니다. 아무리 발전을 꿰하려해도 TCP위에서는 한계가 있기 때문입니다. TCP는 신뢰성은 보장되지만 속도가 느리다는 단점이 있으며, HOLB의 문제가 있었고, 해당 문제를 TCP위에서 해결한다 할지라도 전세계적으로 사용되고 있는 네트워크 기기와의 호환성 문제도 있었습니다. 결국 HTTP/3는 UDP를 선택하게 되었습니다. 

왜 UDP를 선택했을까요? 우선 UDP는 무엇일까요? 아래에서 조금 더 자세히 설명하겠지만, 간략하게 설명드리자면, 데이터 전송의 안정성을 보장하지는 않지만 빠르게 전송할 수 있는 프로토콜입니다. 예를 들면, UDP는 '던진다~! 오케이 나는 던졌어. 받는건 니 책임~'와 같이 데이터를 전송하기 전 재차 확인하는 과정이 없이, 빠르게 데이터를 전송하지만 신뢰성을 보장하지 않는 프로토콜입니다. 반면, TCP는 '야! 받을 준비됐어? 된거 맞지? 그럼 보낼께!'와 재차 확인을 하면서 데이터의 안정성을 보장하면서도 속도가 상대적으로 느린 프로토콜입니다. 

UDP는 빠르다고 할 수 있지만, 데이터의 안정성은 보장못하지 않나요? 맞습니다. TCP에 비해 데이터가 손실될 확률이 높습니다. 하지만 이를 보완할 방법이 있기 때문에 HTTP/3에선 UDP를 선택했겠죠. UDP의 단점은 QUIC이 보완해줍니다. QUIC에 대한 설명과 함께, UDP의 단점은 어떻게 보완되었는지도 설명해보겠습니다. 

### QUIC 

HTTP/3은 UDP위에 설계되었다고 말씀드렸지만, 조금 더 엄밀히 말하면 QUIC이라는 프로토콜 위에 설계되었습니다. 그리고 그 QUIC이 UDP위에 설계된 것입니다. 이 QUIC이라는 프로토콜은 구글에서 실험적으로 만든 프로토콜인데, 이후에 IETF의 관심을 끌고, 표준으로 채택되게 되었습니다. HTTP3를 이루고 있는 기술이 QUIC이고 이 QUIC을 이해하는 것이 곧 HTTP3를 이해하는 것과 다를바가 없다고 할 수 있습니다. 

그렇다면 QUIC에서는 어떤 개선점이 있었을까요? 여러가지가 존재하겠지만, 이전 버전의 한계점을 어떻게 개선했는지를 중점으로 놓고 몇 가지 살펴보도록 하겠습니다. 

다음은 제가 설명드릴 내용의 목차입니다. 

1.빠른 연결 수립 (built-in security)
2.HOLB 문제가 해결된 멀티플렉싱 
3.Connection ID 
4.UDP의 단점을 보완한 QUIC 


### 1.빠른 연결 수립 (built-in security) :

HTTP2의 한계점을 살펴보면서, TCP의 느린 연결수립에 대해서 알아봤었습니다. TCP에서는 기본적으로 연결수립을 진행한 다음, 보안에 대한 연결을 진행합니다. 때문에 최소 2회 이상의 RTT가 발생합니다. 그런데 QUIC는 1RTT 만에 연결수립와 보안을 동시에 진행합니다. 대단하지 않나요? 한번만에, 연결과 보안 둘 다 챙겨버립니다. 이것이 어떻게 가능할까요? 

아래 사진을 보시겠습니다. 

![](https://velog.velcdn.com/images/yesbb/post/83be0200-e7a2-4323-a6a4-7598248a2b16/image.png)

왼쪽 그림을 보면 기존에는 TCP위에 TLS가 독립적으로 존재합니다. 그러나 오른쪽 그림의 QUIC에서는 TLS를 내장하고 있습니다. 이 말인즉, 기존에는 보안 설정을 하기 위해서는 TCP 연결을 수립하고 난 다음, 보안을 위한 추가적인 작업이 필요했지만, QUIC에서부터는 보안을 위해 추가적인 작업을 따로해 줄 필요 없이 기본적으로 내장하고 있게 되었다는 것입니다. 이 때문에 더욱 빠른 연결수립을 하는 것이 가능해졌습니다. 아래의 그림을 보시면 더욱 명확하게 이해될 것입니다.
![](https://velog.velcdn.com/images/yesbb/post/4c9b0b0a-246b-4624-92a2-032257da1b05/image.jpeg)

그림과 같이 QUIC에서는 연결 수립을 위해 처음 보내는 요청에서부터, 보안이 필요한 정보까지 함께 보내고 있습니다. 때문에 연결수립과 보안설정까지 1RTT만에 끝낼 수 있습니다. 심지어 사전에 연결했던 적이 있었다면, 이전의 정보를 캐싱해둠으로써 0RTT도 가능해집니다. [참고](https://www.rfc-editor.org/rfc/rfc8446.html#section-2.3)

이렇듯 QUIC은 TLS1.3 보안 프로토콜의 기능들을 통합함으로써, 암호화의 작업을 어플리케이션 계층에서 전송계층으로 내렸고, 이를 통해서 연결수립의 속도를 높일 수 있었습니다. 추가적으로 보안이 가능해진 영역도 넓어졌는데, 해당 내용은 여기선 다루지 않겠습니다. 

### 2. HOLB가 해결된 멀티플렉싱  : 

HOLB문제는 TCP를 기반으로한 프로토콜의 고질적인 문제점이었습니다. 패킷이 손실되면, 손실된 패킷이 재전송되기 전까지는 전체 데이터 전송의 흐름에 병목이 생길 수 밖에 없었습니다. 

그렇다면 이런 문제를 해결하기 위해 각각의 패킷들도 stream별로 구분해주어야 합니다. 이런 일이 어떻게 가능할까요? HTTP2에서 멀티플렉싱이 이루어진 원리와 비슷합니다. HTTP2에서 어떻게 멀티플렉싱이 가능했나요? 바로 프레임에 stream id를 부여했기 때문에 가능했었습니다. 도착한 프레임의 순서가 막무가내여도, 해당 프레임에 부여된 stream id를 확인해서 각각의 stream에 맞게 프레임을 재조립 해주었기 때문에 요청을 보낸 순서대로, 응답이 도착할 필요가 없었던 것입니다. 그러니까 HTTP2 멀티플랙싱의 핵심은 stream id입니다. 

그리고 QUIC에서의 멀티플렉싱의 핵심도 stream id에 있습니다. 어떻게 QUIC에서는 HOLB가 해결되면서, 멀티플렉싱도 가능해졌는지 차차 알아가봅니다. 

먼저, QUIC으로 들어오면서 멀티플렉싱의 기능이 전송계층으로 내려갔습니다. 기존의 HTTP2에서는 멀티플렉싱의 기능이 어떤 계층에서 이루어졌었죠? 

Binary Framing Layer라는 계층이었습니다. 이 계층은 TCP라는 전송 계층위에, 그리고 application 계층 아래에 있었습니다. 전송계층에서 받아온 패킷 안의 프레임을 가지고 위의 계층으로 보내면, 그 위의 binary framing 계층에서 프레임 안의 stream id를 가지고 조립을 하는 방식이었습니다. 그러니까, Binary Framing Layer에서 멀티플렉싱이 이루어지고 있었습니다. 

그런데, 그 멀티플렉싱이 QUIC에서는 전송계층으로 내려오면서, 각각의 패킷에 대하여, 아니 더 엄밀히 말하면, 패킷이 가지고 있는 byte stream에 대하여 stream id를 부여합니다. 그 stream id 덕분에 패킷들은 독립적인 패킷이 될 수 있습니다. 이 덕분에 멀티플렉싱이 가능해집니다. 무슨 말인지 모르겠죠? 제가 그림과 함께 차근차근 설명해보겠습니다. 

#### TCP에서의 패킷 전송 흐름 : 

![](https://velog.velcdn.com/images/yesbb/post/89e45565-c5bb-4186-b118-dd951e45d736/image.png)

위쪽의 주황색은 TCP에서의 패킷 전송흐름입니다. 위에서 설명드렸다시피, TCP는 신뢰성을 중요하게 생각하는 프로토콜이기 때문에 각각의 패킷들이 순서에 맞게 도착하도록 해야합니다. 그것을 위해서 byte range가 주어져있습니다. 그림을 예로 들어 설명해보겠습니다. 

>
1. packet1이 도착했습니다. byte range가 0-499이네요. 이 사실을 기억합니다. 
2. packet3이 도착했습니다. byte range가 750-1599이네요. 어, 중간에 450-749가 비었습니다. packet2를 재전송 요청합니다. 
3. packet2가 도착할 때까지 이후의 다른 패킷들은 대시 상태에 들어가게 됩니다. 


만약 위의 예시에서 packet1과 packet3 담고 있는 데이터의 종류가 stream1과 관련된 데이터였고, packet2가 담고 있는 데이터의 종류가 stream2와 관련된 데이터였다고 해보겠습니다. 그렇다면 사실 packet2가 손실된 것은 packet1과 packet3의 데이터와는 큰 상관이 없습니다. 애궂게 그냥 기다리는 겁니다. 

#### QUIC에서의 패킷 전송 흐름 : 

그런데 QUIC은 이런 문제를 각각의 패킷에 stream id를 부여함으로써 해결합니다.

![](https://velog.velcdn.com/images/yesbb/post/89e45565-c5bb-4186-b118-dd951e45d736/image.png)

아래쪽의 파란색 그림을 보겠습니다. 아래쪽 그림은 HTTP3를 이루고 있는 QUIC이라는 전송 프로토콜입니다. 여기에선 <u>각각의 패킷마다 그 안에 stream id를 가지고 있습니다. 이게 핵심입니다.</u> 

차근 차근 생각해봅시다. `{packet : 1, streamId : 1, byte : 0-449}` 이 데이터가 먼저 도착했고, 그 다음에 `{packet : 3, streamId: 1, byte : 450-999}`가 도착했습니다. 그러니까 packet 2에 손실이 생긴 것입니다. 
만약 TCP였다면 그대로 다시 packet2를 재전송 요청했을 것입니다. 하지만, QUIC에서는 패킷이 도착한다? <u>그러면 stream id를 먼저 확인합니다.</u> 그런 다음, 이전 stream id에서 가지고 있던 byte range를 확인합니다. 제가 예를 든 패킷을 통해서 순서대로 살펴보겠습니다. 아래의 내용을 차근차근 읽다보면 원리를 이해하게 될 것입니다.

>
1. packet 1이 도착했다.
2. stream id를 확인하니 1번이다. 해당 스트림에 대한 byte range를 기억한다.
3. packet 3이 도착했다.
4. stream id를 확인해보니 1번 stream이다. 그러면 이전에 stream id의 byte range를 확인한다. 확인해보니 0-449다. 지금 받아온 byte range는 450-999다. byte range 사이의 어떤 gap도 존재하지 않는다. 정상이라고 처리한다.
5. packet 4를 받았다.stream id를 확인해보니 2번 stream이다. 그러면 이전에 stream id 2번의 byte range를 확인한다. 어, 그런데 해당 데이터가 존재하지 않는다. 지금 받아온 byte range는 300-599인데, 0-299라는 gap이 존재한다. stream id 2 번에 대한 이전 패킷을 다시 요청해야겠다.
6. stream 2번에 해당하는 이전 패킷을 요청한다. 다시 손실된 패킷을 받아오는 동안, packet 4번의 데이터는 보관된다. 그리고 나머지 상관없는 stream의 패킷에는 지연이 발생하지 않는다. 오로지 Stream 2번과 관련된 패킷에만 지연이 생긴다.

이런 원리를 통해서 http3에서는 TCP 차원에서 발생하던 HOLB의 문제를 해결했습니다. 결국 핵심은 stream id입니다. 이런 고유 번호를 통해서 독립적으로 전송될 수 있도록 하는 멀티플렉싱이라는 기술이 가능해진 것입니다.

여기서 깨알같이 저희가 알 수 있는 사실은 HTTP3가 udp를 사용함에도 불구하고 <u>순서를 보장한다는 사실</u>입니다. 모든 패킷들에 대해서 순서를 지키도록 하는 것은 아니고, 각 스트림에 대해서는 순서를 지키도록 하면서 QUIC은 신뢰성을 보장하고 있습니다. 


아래는 제가 http3에서의 멀티플렉싱을 이해하기 위해 참고한 자료들입니다. 

- [Head-of-Line Blocking in QUIC and HTTP/3: The Details](https://calendar.perfplanet.com/2020/head-of-line-blocking-in-quic-and-http-3-the-details/) <- holb관련해선 이 자료가 최고인 것 같습니다.. 👍
- [TCP Head of Line Blocking](https://http3-explained.haxx.se/en/why-quic/why-tcphol)
- [QUIC and HTTP/3 Features - Head of Line Blocking Removal](https://github.com/rachinkapoor/http3_and_quic_blogs/blob/main/4_quic_head_of_line_blocking_removal.md) 

<br/>

### 3.Connection ID :


### 4.UDP의 단점을 보완한 QUIC 

https://www.debugbear.com/blog/http3-quic-protocol-guide#tcp-vs-udp => 이 자료에선 TCP와 UDP를 잘 비교해주고 있다. 또한 UDP의 단점까지도 잘 설명해준다. 

https://www.debugbear.com/blog/http3-quic-protocol-guide#why-do-we-need-quic => 여기서는 QUIC이 어떻게 UDP의 단점을 보완하면서도 TCPD의 장점을 챙겼는지에 대해서 설명하고 있다. 

HTTP3 참고자료 : 
- [](https://www.debugbear.com/blog/http3-quic-protocol-guide)
- https://pcarleton.com/2018/06/03/quic/



[RFC9110](https://www.rfc-editor.org/rfc/rfc9110.html#name-connections-clients-and-ser)
[Understanding Application Layer Protocols](https://www.informit.com/articles/article.aspx?p=169578)
[HTTP의 진화](https://developer.mozilla.org/ko/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP)
[구글의 야심작](https://www.secmem.org/blog/2022/01/03/quic/#%EA%B5%AC%EA%B8%80%EC%9D%98-%EC%95%BC%EC%8B%AC%EC%9E%91-quic)
[Evolution of HTTP](https://medium.com/platform-engineer/evolution-of-http-69cfe6531ba0)
[Brief History of HTTP](https://hpbn.co/brief-history-of-http/)
[Why the Internet will be faster with HTTP/2](https://stileex.xyz/en/why-internet-faster-http-2/)
[ideal HTTP Performance](https://www.mnot.net/blog/2016/04/22/ideal-http)
[The Performance Of HTTP Requests Over HTTP/1.1](http://vanseodesign.com/web-design/http-requests/)
[HTTP/2](https://www.imperva.com/learn/performance/http2/)

[The Evolution of HTTP – HTTP/2 Deep Dive](https://ably.com/topic/http2)

[http3 quic protocol guide](https://www.debugbear.com/blog/http3-quic-protocol-guide)
[http3 is fast](https://requestmetrics.com/web-performance/http3-is-fast)